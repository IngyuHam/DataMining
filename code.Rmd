---
title: "데이터마이닝 팀 과제 : 수질 데이터를 활용한 안전한 물 분류"
author: "팀 피날레"
output: 
  html_document:
    toc : true 
    toc_float : true 
---

***

# A. 과제 개요 
* 수질 분석의 필요성 
  + 물은 생명의 생존 문제와 직결되어 있다. 우리가 마시는 물은 뇌와 폐, 심장 등 각종 기관으로 운반되어 생명 유지 활동에 쓰이고, 노폐물을 배출해 건강을 유지해준다. 그러나 오염된 물의 섭취는 오히려 면역력을 감소시켜 A형 간염, 콜레라 등의 감염병을 일으킨다. 질병 관리청에 따르면, 우리나라 수인성 질병 사례 건수는 2020년 234건, 2021년 402건, 2022년 429건으로 코로나 이후 꾸준히 증가하고 있다. 
  + [질병관리청 : 수인성식품매개감염병관리](https://www.kdca.go.kr/contents.es?mid=a20301030000)
  
  + 따라서 깨끗한 물 즉, 음용수를 판별하는 일은 인류의 건강 보호에 필수적인데, 깨끗한 물의 공급은 오염된 물로 인한 질병 예방으로 이어져 의료비를 절감하고, 농업, 하수처리 사업 등 각종 산업 분야에서도 유용하게 사용되어 노동력 생산성이 향상되고 경제적 이익을 기대할 수 있기 때문이다.


\

* 과제 최종목표
  + 수질 데이터셋으로부터 기계 학습을 통해 수질에 많은 영향을 끼치는 변수가 무엇인지 파악하여 수질을 측정하고, 물의 소비 가능성을 평가, 예측한다. 또한, 물의 소비에 대한 안전성과 적합성을 평가함으로써 수질 기준을 준수한 물 처리 의사 결정을 돕는다. 



\
\
\

***

# B. 데이터 설명 
* 데이터 출처
  + [Kaggle Dataset : Water quality](https://www.kaggle.com/datasets/mssmartypants/water-quality) 
  + 위 데이터셋은 kaggle 사이트에 등재되어 있는 수질 데이터셋으로, 실제 도심 환경의 수질 데이터에 기반해 교육 및 실습 목적으로 재가공하였다. 수질 평가에 실제로 고려되는 변수들이 들어가 있어 해당 도메인 지식이 부족한 사람들이 관련 지식을 습득하는데 도움을 준다.
  

\


* 변수 설명
  + aluminium(알루미늄) : 2.8 이상이면 위험하다고 판단하며, 수돗물의 응집제로 쓰인다.
  
  + ammonia(암모니아) : 32.5 이상이면 위험하다고 판단하며, 강한 부식성이 있는 맹독성 물질로 물에 잘 흡수되는 특성이 있다. 
  
  + arsenic(비소) : 0.01 이상이면 위험하다고 판단하며,독성이 있으며,대부분의 일반적인 비소 화합물이 물에 용해된다.
  
  + barium(바륨) : 2 이상이면 위험하다고 판단하며, 물과 반응하여 수소 기체를 발생한다.
  
  + cadmium(카드뮴) : 0.005 이상이면 위험하다고 판단하며, 독성물질이어서 체내에 흡수될 경우 중독증상을 일으킨다.
  
  + chloramine(클로라민) : 4 이상이면 위험하다고 판단하며, 물 정화에 쓰이는 암모니아와 염소가 반응했을 때 생성된다. 
  
  + chromium(크로뮴) : 0.1 이상이면, 위험하다고 판단하며, 염색이나 페인트의 소재로 쓰인다. 종종 토양이나 지하수로 버려진다. 
  
  + copper(구리) : 1.3 이상이면 위험하다고 판단하며, 체내에 축적될 경우 윌슨병의 위험이 있다. 
  
  + flouride(플루오린화합물) : 1.5 이상이면 위험하다고 판단하며, 독성물질이어서 체내에 흡수될 경우 중독증상을 일으킨다.
  
  + bacteria(박테리아) : 0 이상이면 위험하다고 판단한다. 
  
  + viruses(바이러스) : 0 이상이면 위험하다고 판단한다. 
  
  + lead(납) : 0.015 이상이면 위험하다고 판단하며, 중독의 위험성이 있는 유해물질이다. 
  
  + nitrates(질산염) : 10 이상이면 위험하다고 판단하며, 산화제·화학 비료로 쓰이고, 지하수에 흘러 들어갈 경우 부영양화를 일으킨다. 
  
  + nitrites(아질산염) : 1 이상이면 위험하다고 판단하며, 산업 공정 용수 및 냉각탑에서 부식 억제제로 사용된다.
  
  + mercury(수은) : 0.002 이상이면 위험하다고 판단하며, 중독 위험성이 있는 유해물질이다. 
  
  + perchlorate(과염소산염) : 56 이상이면 위험하다고 판단하며, 갑상선암을 유발하는 독성물질이다. 
  
  + radium(라듐) : 5 이상이면 위험하다고 판단하며, 방사능 물질이다. 
  
  + selenium(셀레늄) : 0.5 이상이면 위험하다고 판단하며, 체내에 과다하게 쌓일 경우 중독증상을 일으킨다. 
  
  + silver(은) : 0.1 이상이면 위험하다고 판단하며, 체내 속 수분과 반응해서 만들어지는 은화합물로 인해 중독증상이 나타난다. 
  
  + uranium(우라늄) : 0.3 이상이면 위험하다고 판단하며, 방사능 물질이다. 오염수를 섭취함으로써 노출되기도 한다. 
  
  + is_safe : 0 = 안전하지 않다. 1 = 안전하다. 



\
\
\

***

# C. 데이터 분석  
## 0. 패키지
```{r, message = FALSE}
library(InformationValue)
library(rmarkdown)
library(MASS)
library(car)
library(ROSE)
library(corrplot)
library(DataExplorer)
library(tidyverse)
library(caret)
library(reshape2)
library(pROC)
library(rpart)
library(rpart.plot)
library(partykit)
library(scorecard)
library(randomForest)
```



\

## 1. EDA(Exploratory Data Analysis)
```
모델링 작업하기 전에 분석의 대상이 되는 데이터를 탐색함으로써 데이터셋의 특징을 파악하는 과정으로, 
데이터의 특성, 패턴, 이상치, 변수 간의 관계 등을 조사한다. 주로 시각화와 통계적 도구를 활용하여 데이터의 구조와 패턴을 탐색한다. 
```
### 1.1) 데이터 전처리 
#### __데이터 불러오기__ 
```{r}
water_qual <- read.csv("./waterQuality1.csv")
str(water_qual)
```

> csv 파일에서 ammonia은 연속형 변수 형태인데 R에서는 chr형으로 불러왔고, 클래스 변수인 is_safe가 chr형이다. 따라서 ammonia는 numeric형으로, is_safe는 factor형으로 변환한다. 또한, 직관성을 고려하여 is_safe의 이름도 safety로 변경한다. 

\

```{r}
water_qual$is_safe <- as.factor(ifelse(water_qual$is_safe == "1", 1, 0))
names(water_qual)[names(water_qual) == "is_safe"] <- "safety"
water_qual$ammonia <- as.numeric(water_qual$ammonia)
str(water_qual)
```

\

#### __결측치 확인__ 
```{r, message = FALSE}
plot_missing(water_qual,geom_label_args = list("size" = 3), group = list("1. None" = 0, "2. A few" = 0.05, "3. Some" = 0.2, "4. Many" = 1))
```

> ammonia 변수를 numeric형으로 변환한 결과, 결측치가 3개 발생했다. 따라서 결측치를 제거한다. 

\

```{r}
water_qual <- na.omit(water_qual)

plot_missing(water_qual,geom_label_args = list("size" = 3), group = list("1. None" = 0, "2. A few" = 0.05, "3. Some" = 0.2, "4. Many" = 1))
```

\

#### __Boxplot을 통한 이상점 유무 확인__
```{r, message=FALSE, fig.align='center'}
melt(water_qual) %>% ggplot(aes(variable,value)) + geom_boxplot(alpha = .5, fill = "skyblue", width = 0.4) + facet_wrap(~variable, scales="free") + stat_summary(fun = "median", geom = "point", color = "orange", size = 2) + theme(axis.title.x = element_blank(), axis.title.y = element_blank()) + theme_bw()
```

> aluminium 변수와 arsenic 변수에서 이상점이 많이 발견되고 있다. 따라서 이상점이 차지하는 비율을 계산해서 확인한다.  

\

#### __전체 데이터 중에서 이상점이 차지하는 비율 확인(0개인 변수는 제외)__
```{r}
outlier_rat <- water_qual[,-21] %>% 
  summarise_all(function(x) sum(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x)) / length(x))

outlier_rat <- outlier_rat[,outlier_rat > 0]

outlier_rat
```

> aluminium 변수와 arsenic 변수에서 이상점 비율이 0.2를 넘고 있다. 이상점 비율이 적은 경우에는 이상점을 제거해서 모델 학습 시 정확도를 향상시킬 수 있지만, 지금처럼 많은 경우에 섣불리 제거하면 향후 validation 단계에서 추정의 정확도가 낮을 것으로 우려된다. 따라서 본 프로젝트에서는 이상점을 제거하지 않고 그대로 활용하기로 한다.  

\

### 1.2) 데이터 탐색
#### __밀도함수 그래프를 통한 설명변수의 분포 관찰__
```{r, message=FALSE, fig.align='center'}
melt(water_qual) %>% ggplot(aes(value, fill = safety)) + geom_density(alpha = 0.7) + facet_wrap(~variable, scales = "free") + 
  theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank()) + scale_fill_brewer(palette="Dark2")
```

> aluminium, barium, cadmium, chloramin, chromium, copper, perchlorate, radium, silver, uranium 총 10개의 변수에 대해서 safety 별로 밀도함수가 다르게 그려지는 것으로 판단된다. 따라서 해당 변수들은 수질에 영향력을 끼칠 것으로 예상된다. 

\

#### __safety 클래스 별 설명변수의 Boxplot__
```{r, message=FALSE, fig.align='center'}
melt(water_qual) %>% ggplot(aes(variable,value, fill = safety)) + geom_boxplot() + facet_wrap(~variable, scales="free") + theme(axis.title.x = element_blank(), axis.title.y = element_blank()) + theme_bw()
```

> aluminum, cadmium, chloramine, chromium의 경우, 그림의 형태와 중앙값의 위치에서 차이가 발생하고 있다. 
perchlorate, uranium의 경우, 그림의 형태는 비슷하나 중앙값의 위치에서 차이가 상당하다.  

\

#### __설명변수 간의 상관관계 확인__
```{r, fig.align='center'}
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor(water_qual[,-21]), method="shade", tl.srt=45, col=col(100), shade.col=NA, type = "upper", order = "FPC", addCoef.col="black", number.cex = 0.6)
```

* bacteria & viruses = 0.62
* chloramine & perchlorate = 0.59
* chloramine & chromium = 0.56
* perchlorate & chromium = 0.52
* chloramine & silver = 0.52 
* perchlorate & silver = 0.5
* chromium & silver = 0.51 

\

#### __클래스 불균형 확인__ 
```
target 변수에서 클래스 간의 비율이 균형을 이루지 않을 경우, 
모델 학습 시 다수 클래스에 편승해서 예측하는 경우가 발생한다. 
따라서 추정의 정확성을 높이기 위해 클래스 불균형을 확인한다. 
```
```{r, fig.align='center'}
water_qual %>%
    select(safety) %>% count(safety) %>% mutate(rate = (n/sum(n)*100)) %>%
    ggplot(aes(x = "", y = rate, fill = safety, label = rate)) +
    geom_bar(stat = "identity", color = "black") + 
    coord_polar("y") + theme_void() + geom_text(aes(y = c(65, 5), label = c("     not safe\n", "  safe\n\n")), size = 5) + 
  geom_text(aes(y = c(60, 6), label = paste(round(rate, 1),"%")), size = 5, color = "black") + scale_fill_brewer(palette="Pastel1")
```

```{r, echo = TRUE}
summary(water_qual$safety)
```

> safe의 비율이 not safe에 비해 굉장히 부족해 클래스 불균형이 심해서 관측치의 개수를 조정할 필요가 있다. 


\


#### __클래스 별 관측치 개수 조정__ 
```
관측치 개수 조정에는 오버샘플링과 언더샘플링이 있다. 오버샘플링은 소수 클래스의 관측치 개수를 늘리고, 언더샘플링은 다수 클래스의 관측치 개수를 줄인다. R의 ROSE 패키지는 오버샘플링과 언더샘플링을 동시에 진행하여 원래 데이터 개수에 맞추어 클래스 비율을 재조정한다. 단, 언더샘플링은 다수 클래스에 대한 정보 손실이 발생할 수 있으므로, 완전히 균형을 이루는 것은 지양하고 5:5와 9:1의 중간인 7:3 비율을 사용한다.   
```
```{r}
waterbal <- water_qual
waterbal <- ROSE(safety ~ ., data = water_qual, p = 0.30, seed = 2023)$data
```

```{r, fig.align='center'}
waterbal %>%
    select(safety) %>% count(safety) %>% mutate(rate = (n/sum(n)*100)) %>%
    ggplot(aes(x = "", y = rate, fill = safety, label = rate)) +
    geom_bar(stat = "identity", color = "black") + 
    coord_polar("y") + theme_void() + geom_text(aes(y = c(65, 11), label = c("     not safe\n", "safe\n\n")), size = 5) + 
  geom_text(aes(y = c(60, 12), label = paste(round(rate, 1),"%")), size = 5, color = "black") + scale_fill_brewer(palette="Pastel1")
```

```{r, echo = TRUE}
summary(waterbal$safety)
```



\
\


#### __데이터 정규화__ 
```
변수 간의 단위 차이가 크면, 모델 학습 시 상대적으로 단위가 큰 변수에 영향을 더 많이 받을 수 밖에 없다. 따라서 표준화나 정규화를 통해 변수 간의 범위를 조정해야 한다. 본 프로젝트에서는 원래 변수들이 모두 양수임을 고려하여 정규화를 통해 각 변수들이 0에서 1사이의 값을 갖도록 한다. 
```
```{r}
# 정규화 전, 변수들의 범위를 summary 함수로 파악  
summary(waterbal)
```

```{r}
# caret 패키지의 preProcess 함수를 사용해서 정규화를 진행
normal_dat <- preProcess(waterbal[,-21], method = "range")
water_model <- predict(normal_dat, waterbal)

# 정규화 후, 변수들의 범위를 summary 함수로 파악  
summary(water_model)
```

> 모든 변수들이 0 ~ 1 사이의 값을 갖는 것을 확인했다. 



\
\

***

## 2. Modeling
### 2.1) Split data
```
training : validation = 7 : 3으로 지정해서 데이터를 나눈다. 
```
```{r}
set.seed(2023)

idx <- createDataPartition(water_model$safety, p = 0.7, list = FALSE)

train <- water_model[idx, ]
validate  <- water_model[-idx, ]
```


\
\

***



### 2.2) Random Forest
#### __모델 세우기__ 
##### __*초기 모델 작성*__
```{r}
set.seed(2023)

rf_water <- randomForest(safety~.,data=train, importance=TRUE)
```

\

##### __*Tree 수에 따른 Error rate 시각화*__
```{r}
plot(rf_water, main="Tree 수에 따른 Error Rate")

legend(x=420, y = 0.37, legend = colnames(rf_water$err.rate),fill = 1:ncol(rf_water$err.rate))
```

> OOB(Out-of-Bag) Error은 부트스트랩 샘플링을 통해 훈련된 각 트리에 대해 사용되지 않은 데이터를 사용하여 에러를 계산한 값으로, 새로운 데이터에 대한 일반화 정도를 측정하는데 사용된다. 0과 1은 클래스 별 에러를 의미한다. Tree 수가 증가할수록 Error Rate는 점점 감소하고 있다. 특히, Tree 수가 100을 넘어가는 이후부터는 거의 일정하다.  


\

##### __*튜닝 1 : mtry의 최적값 찾기*__
* Accuracy를 최대화하는 튜닝을 진행한다. 
* mtry : 랜덤 포레스트 모델에서 각 분기마다 사용될 변수의 수
* method = bootstrap : 부트스트랩 방법을 사용한다. 부트스트랩은 데이터를 무작위로 복원 추출하여 여러 훈련 세트를 생성하여 모델을 훈련시키는 것으로, 다양성 확보와 과적합 방지에 효과적이다. 
* search = random : 모델의 하이퍼파라미터 튜닝을 위해 무작위로 다양한 값들을 넣는다. 이는 모든 조합을 시도하는 그리드 탐색과 달리, 무작위로 샘플링된 하이퍼파라미터 조합을 평가하기 때문에 계산 비용이 적다.  


```{r}
set.seed(2023)

x <- train[,1:20]
y <- train[,21]

metric <- 'Accuracy'

mtry<-sqrt(ncol(x))

control <- trainControl(method = 'boot', search = 'random')

rf_random <- caret::train(safety ~ ., data = train, method = 'rf', metric = metric, tuneLength = 25, trControl = control)
```

```{r}
plot(rf_random)
```

> mtry=8 or 9일 때, accuracy와 Kappa 통계량이 가장 크다. kappa 통계량은 분류 모델의 성능을 측정하는 통계량으로, 둘 이상의 모델 간의 일치도를 측정하는 데 사용된다. -1 ~ 1 사이의 값을 가지며, 1에 가까울수록 일치도가 높다. 

```{r}
set.seed(2023)

OOBmtry <- tuneRF(x,y)
```

> OOB Error rate를 최소로 하는 mtry 역시 8로, 위 결과와 동일하다. 따라서 random 방식에 의하면, mtry = 8로 정하는 것이 타당하다. 이제 tree의 수를 결정하자. 

\

##### __*튜닝 2 : model customizing을 통해 (mty, ntree) 쌍 결정*__ 
* [customizing model](https://topepo.github.io/caret/using-your-own-model-in-train.html) 
* 위 문서를 참고해서 random forest model을 직접 만든다. 
* mtry : 랜덤 포레스트 모델에서 각 분기마다 사용될 변수의 수, 위 결과를 토대로 8과 9를 가져가고 다양성을 확보하기 위해 mtry에 대한 여러가지 경우의 수를 고려한다. 
* ntree : 의사결정 트리의 개수

```{r}
x <- train[, 1:20]
y <- train[, 21]

metric <- 'Accuracy'

control <- trainControl(method = 'boot', search = 'grid')
```

```{r}
customRF <- list(type='Classification', library='randomForest', loop=NULL)
customRF$parameters <- data.frame(parameter = c('mtry','ntree'), class = rep('numeric',2), label = c('mtry','ntree'))
customRF$grid <- function(x, y, len = NULL, search = 'grid'){}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs,...){
  randomForest(x, y, mtry = param$mtry, ntree = param$ntree,...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL){predict(modelFit,newdata)}
customRF$prob <- function(modelFit,newdata,preProc = NULL,submodels = NULL){predict(modelFit, newdata, type='prob')}
customRF$sort <- function(x){x[order(x[,1]),]}
customRF$levels <- function(x){x$classes}
control <- trainControl(method = 'boot', search = 'grid')
tunegrid <- expand.grid(.mtry=c(sqrt(ncol(x))/2, sqrt(ncol(x))*2, sqrt(ncol(x)), 8, 9), .ntree=seq(from = 50,to = 500,by = 50)) 
```

```{r}
set.seed(2023)

custom<-caret::train(safety~.,data=train,method=customRF,metric=metric,tuneGrid=tunegrid,
              trControl=control)
```

```{r}
plot(custom)
```

> mtry = 8.944... = sqrt(ncol(x)) * 2, ntree = 300일 때, 정확도가 최대값을 갖는다. 따라서 해당 파라미터를 넣은 모델을 최종 모델로 선택한다.  

\

##### __*최종 모델*__ 
```{r}
set.seed(2023)

rf_final<-randomForest(safety ~ .,data = train, mtry = sqrt(ncol(x))*2, ntree = 300, importance = TRUE)
```

\

#### __모델 평가__ 
##### __*Confusion Matrix*__
```{r}
rf_pred <- predict(rf_final, type = "class", newdata = validate[,-21])
rf_mat <- confusionMatrix(rf_pred, validate$safety, positive = "1")
rf_mat
```

* Acurracy = 0.8394
* Sensitivity = 0.5914
* Specificity = 0.9417

\

##### __*Variance Importance*__
* MeanDecreaseAccuracy : 모델 학습 시 각 변수의 초기 중요도를 설정한 후, 각 변수들이 섞이거나 제외된 상태에서의 모델 정확도 감소량을 측정하고 평균을 낸다. 평균 감소 정확도가 높은 변수를 중요한 변수로 간주한다.  
* MeanDecreaseGini : 어떤 변수 x로 트리를 분할하였을 때, 오차가 얼마나 줄었는지를 모든 트리에 대해 확인한다. 오차가 줄어든만큼 가산점을 부여해서 가장 많은 점수를 획득한 변수 순서대로 중요하다고 판단한다. 
```{r}
varImpPlot(rf_final)

varimp_rf <- as.data.frame(importance(rf_final))
paged_table(varimp_rf)
```

> 정확도와 지니계수 모두 aluminium, arsenic, cadmium 순으로 중요한 것으로 나타났다. 따라서 해당 변수들이 수질에 영향을 끼칠 것으로 판단된다. 

\

##### __*ROC curve*__
```{r, message=FALSE}
rf.roc <- roc(response = validate$safety, predictor = as.numeric(rf_pred))
plot(rf.roc, legacy.axes = TRUE, print.auc.y = 1.0, print.auc = TRUE, xlab = "False Positive Rate",
     ylab = "True Positive Rate")
```


\

##### __*KS-test*__
```{r, warning=FALSE}
ks_rf <- ks.test(as.numeric(rf_pred[validate$safety == 0]), as.numeric(rf_pred[validate$safety == 1]))
ks_rf
```
> 가설 검정 결과 : 검정통계량 = 0.53312, p-value < 2.2e-16으로, safety = 1인 그룹과 safety = 0인 그룹 간 유의미한 분포 차이가 있다고 할 수 있다.


\
\

*** 

### 2.3) Decision Tree
#### __모델 세우기__
```{r}
# Train data로 훈련시키기 
tree <-  rpart(safety ~., data = train)

plotcp(tree)
```

> tree size = 6, cp = 0.012일 때, xerror 값이 최소이다. 따라서 이 결과를 이용하되, Entropy를 기준으로 split을 진행한다. Entropy는 클래스 불균형이 클 때 유용하다. 


```{r}
# cp = 0.012 일 때의 decision tree model 
tree_final <-  rpart(safety ~., data = train, control = rpart.control(cp = 0.012, method = "information"))
```


\

#### __Dicision tree 시각화__ 
```{r, fig.align='center'}
tree.party <- as.party(tree_final)

tree.party

plot(tree.party)
```

> alumnium, arsenic, cadmium, perchlorate, ammonia 5가지의 변수만으로 분류가 되었다. 따라서 수질을 판단하는 데 해당 변수들이 영향을 끼치는 것으로 판단된다.  

\


#### __모델 평가__
##### __*Confusion Matrix*__
```{r}
# validation data로 검증 
tree_pred <- predict(tree_final, type = "class", newdata = validate[,-21])

# 혼동행렬 그리기 
tree_mat <- confusionMatrix(tree_pred, validate$safety, positive = "1")
tree_mat
```

* Accuracy = 0.8194
* Sensitivity = 0.4914
* Specificity = 0.9547


\

##### __*Variance Importance*__
```{r, fig.align='center'}
tree.varimp <- tree_final$variable.importance

tree.varimp <- as.data.frame(tree.varimp)

# 분류에 참여한 17개 변수들의 중요도를 시각화 
tree.varimp6 <- head(tree_final$variable.importance, 17)
barplot(sort(tree.varimp6), main = "Variable Importance", col = "skyblue", las = 1, horiz = TRUE, cex.names = 0.75)

paged_table(tree.varimp)
```

> aluminum의 중요도가 다른 변수에 비해 굉장히 높은 것으로 나타났고, 그 뒤를 이어 arsenic, cadmium의 중요도가 비슷하게 높은 것으로 나타났다. 위 3개의 변수의 비중이 거의 대부분을 차지하고 있고, perchlorate부터는 중요도가 그렇게 크지는 않은 것으로 보인다. 

\


##### __*ROC curve*__
```{r, message = FALSE}
tree.roc <- roc(response = validate$safety, predictor = as.numeric(tree_pred))
plot(tree.roc, legacy.axes = TRUE, print.auc.y = 1.0, print.auc = TRUE, xlab = "False Positive Rate",
     ylab = "True Positive Rate")
```

\


##### __*KS-test*__
```{r, warning=FALSE}
ks_tree <- ks.test(as.numeric(tree_pred[validate$safety == 0]), as.numeric(tree_pred[validate$safety == 1]))
ks_tree
```

> 가설 검정 결과 : 검정통계량 = 0.44608, p-value < 2.2e-16으로, safety = 1인 그룹과 safety = 0인 그룹 간 유의미한 분포 차이가 있다고 할 수 있다.

\
\

***

### 2.4) Logistic Regression
#### __모델 세우기__
```{r}
logit_water <- glm(safety ~ ., data = train, family = binomial)
summary(logit_water)
```
> 현실적으로 20개의 변수를 모두 활용하는 것은 비효율적이고, 통계적으로 유의미하지 않은 변수들이 모형식에 들어감으로써 추정의 정확성을 떨어뜨릴 가능성이 있다. 따라서, 변수를 줄이면서도 추정의 정확성을 향상시키기 위해 변수선택법을 활용하기로 한다.  


\

##### __*변수 선택 : stepAIC*__ 
* AIC (Akaike Information Criterion)를 기반으로 하는 변수 선택 작업을 수행한다. 
* AIC는 모델의 적합도와 모델의 복잡성을 고려하여 모델을 평가하는 통계적 지표임. 
* 변수가 추가될 때, AIC가 감소하는지를 확인해서 모델을 향상시키는 변수를 선택한다. 
* vif는 다중공선성 변수들 간의 다중공선성 정도를 수치화한 것으로, 10 이상이면 다중공선성이 존재한다고 해석한다. 
* direction = both로 지정하면, 변수 추가와 제거를 반복하면서 AIC가 최소화되는 변수 조합을 찾는다. 
```{r, results='hide'}
logit_water_2 <- stepAIC(logit_water, direction="both")
```

```{r}
summary(logit_water_2)
```

> lead, bacteria, flouride 세 변수를 제외한 모델의 AIC 값이 가장 낮은 것으로 나타났다. 여기서 barium, radium, silver에 대한 p-value가 0.05보다 커서 통계적으로 유의하지 않으므로, 해당 변수들은 제거한다. 


\


##### __*통계적으로 유의하지 않은 변수를 제거한 모델*__
```{r}
logit_water_3 <- glm(safety ~ aluminium + ammonia + arsenic + 
    cadmium + chloramine + chromium + copper + viruses + nitrates + 
    nitrites + mercury + radium + selenium + 
    uranium, family = binomial, data = train)
```

```{r}
summary(logit_water_3)
```

> 다중공선성은 여전히 존재하기 않고, 모든 변수들이 통계적으로 유의하다. 그러나 mercury의 p-value 값이 유독 다른 변수들에 비해 작게는 몇십 배, 크게는 몇만 배까지 차이나고 있다. 이에 mercury를 제외하고 모형의 confusion matrix를 출력한 결과, 오분류율이 훨씬 줄어든 것을 확인해서 최종 모델을 다음과 같이 설정한다.  


\


##### __*최종 모델*__ 
```{r}
logit_water_4 <- glm(safety ~ aluminium + ammonia + arsenic + 
    cadmium + chloramine + chromium + copper + viruses + nitrates + 
    nitrites + radium + selenium + 
    uranium, family = binomial, data = train)
```

```{r}
summary(logit_water_4)
```

```{r}
logit_final <- logit_water_4
```


\

#### __모델 평가__ 
##### __*Confusion Matrix*__
```{r, results='hide'}
# validation data로 예측 수행
pred <- predict(logit_final, newdata = validate[,-21])

# 분류 최적값 구하기 : 최적값보다 높으면, 1로 분류 
optimal <- optimalCutoff(validate$safety, pred)[1]
```

```{r}
pred_result <- as.factor(ifelse(pred >= optimal, "1", "0"))
actual_result <- as.factor(ifelse(validate$safety == 1, "1", "0"))

logit_mat <- confusionMatrix(pred_result, actual_result, positive = "1")
logit_mat
```

* Accuracy = 0.7973
* Sensitivity = 0.5529
* Specificity = 0.8981


\

##### __*Variance Importance*__
```{r}
logit.varimp <- varImp(logit_final) 

name <- rownames(logit.varimp)

logit.varimp <- data.frame(name, importance = sort(logit.varimp$Overall, decreasing = TRUE))
```

```{r}
ggplot(logit.varimp, aes(x = importance, y = reorder(name, importance))) + geom_bar(stat = "identity", fill = "steelblue") + labs(title = "", x = "", y = "") + theme_bw()

paged_table(logit.varimp)
```

> alumnium의 중요도가 가장 크고, 나머지 변수들의 중요도 순서는 decision tree와 다른 것을 확인할 수 있다.   


\


##### __*ROC curve*__
```{r, message=FALSE}
glm.roc <- roc(response = actual_result, predictor = as.numeric(pred_result))
plot(glm.roc, legacy.axes = TRUE, print.auc.y = 1.0, print.auc = TRUE, xlab = "False Positive Rate",
     ylab = "True Positive Rate")
```

\

##### __*Scoring & Scorecard*__
```{r}
score_val <- data.frame(score=pred, pred_safety=pred_result, actual_safety = actual_result)
paged_table(score_val)
```

```{r, message=FALSE, results=FALSE}
bins <- woebin(water_model, y = "safety")
score_card <- scorecard(bins, logit_final)
```

```{r}
for (var_name in names(score_card)) {
  result <- score_card[[var_name]] %>% select(c(variable, bin, points)) 
  print(result)
}
```

> aluminium, arsenic, cadmium, chloramine에 대한 score point가 다른 변수들에 비해 많이 높다. 따라서 해당 변수들은 수질에 영향을 끼칠 것으로 예상된다.  

\

##### __*KS-test*__
```{r}
ks_logit <- ks.test(pred[validate$safety == 0], pred[validate$safety == 1])
ks_logit
```
> 가설 검정 결과 : 검정통계량 = 0.50548, p-value < 2.2e-16으로, safety = 1인 그룹과 safety = 0인 그룹 간 유의미한 분포 차이가 있다고 할 수 있다.

***


\
\
\




## 3. 모델 간 비교 및 최종 모델 선택 
### 3.1) Confusion Matrix
* Accuracy = 전체 샘플 중에서 올바르게 예측한 샘플의 비율 -> (TP + TN) / (TP + FP + TN + FN)
* Sensitivity(or Recall) = 실제 True 중에서 옳게 예측된 True의 비율 -> TP / (TP + FN)
* Specificity = 실제 False 중에서 옳게 예측된 False의 비율 -> TN / (TN + FP)
```{r}
# decision tree model의 Accuracy, Sensitivity, Specificity
tree_acc <- tree_mat$overall[1]
tree_sens <- tree_mat$byClass[1]
tree_spec <- tree_mat$byClass[2]

# logistic regression model의 Accuracy, Sensitivity, Specificity
log_acc <- logit_mat$overall[1]
log_sens <- logit_mat$byClass[1]
log_spec <- logit_mat$byClass[2]

# random forest model의 Accuracy, Sensitivity, Specificity
rand_acc <- rf_mat$overall[1]
rand_sens <- rf_mat$byClass[1]
rand_spec <- rf_mat$byClass[2]
```


```{r}
eval_df <- data.frame(model = as.factor(c("Decision Tree", "Logistic Regression", "Random Forest")), 
                      accuracy = c(tree_acc, log_acc, rand_acc),
                      sensitivity = c(tree_sens, log_sens, rand_sens),
                      specificity = c(tree_spec, log_spec, rand_spec))


print(eval_df)
```


```{r}
eval_tidy <- gather(eval_df, indicators, values, -model)

ggplot(eval_tidy, aes(x = model, y = values, fill = indicators)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8) + labs(title = "", x = "", y = "") + theme_bw() + 
  scale_fill_manual(values = c("accuracy" = "#990033", "sensitivity" = "#006633", "specificity" = "#336699"), guide = "none") +
  scale_x_discrete(labels = c("Decision Tree" = "DT","Logistic Regression" = "LR","Random Forest" = "RF")) + facet_grid(.~indicators) +
  geom_text(aes(label = round(values,3), vjust = -0.25))
```

> accuracy와 sensitivity는 Random Forest가 가장 높고, specificity는 Decision Tree가 가장 높다.  

\



### 3.2) AUROC Curve
```{r}
plot(glm.roc, legacy.axes = TRUE, print.auc.x = 0.7, print.auc.y = 0.9, print.auc = TRUE, xlab = "False Positive Rate",
     ylab = "True Positive Rate")
plot(tree.roc, col = "blue", add = TRUE, print.auc.x = 1.0, print.auc.y = 0.8, print.auc = TRUE)
plot(rf.roc, col = "red" , add = TRUE, print.auc.x = 0.4, print.auc.y = 1.02, print.auc = TRUE)
legend(x = 0.01, y = 0.7, c("Random Forest", "Decision Tree", "Logistic"),
       lty = c(1,1), lwd = c(2, 2), col = c("red", "blue", "black"), cex = 0.75)
```

> AUC 값이 크면, threshold 변화에 둔감해서 분류 작업을 잘 수행한다고 할 수 있다. Decision Tree와 Logistic Regression의 AUC 차이는 0.002로 거의 비슷하고, Random Forest의 AUC는 앞선 두 모델보다 명백히 높은 값을 보이고 있다. 


\


### 3.3) KS(kolmogorov–smirnov) test
```{r}
ks_stat <- data.frame(model = c("Decision Tree", "Logistic Regression", "Random Forest"),
                      statistics = c(ks_tree$statistic, ks_logit$statistic, ks_rf$statistic))

print(ks_stat)
```


> Random Forest의 ks 통계량이 가장 높으므로, 해당 모델을 사용했을 때 safety에 따른 데이터의 분포를 가장 잘 구분해서 분류 작업을 잘 수행한다고 할 수 있다.  


\


***

### 3.4) 최종 모델 선택 

* Accuracy 기준 : Random Forest를 선택
* Sensitivity 기준 : Random Forest를 선택
* Specitivity 기준 : Decision Tree를 선택
* AUROC 기준 : Random Forest를 선택
* KS statistic 기준 : Random Forest를 선택

> 총 5가지 지표를 종합하면, 4개의 지표에 대해서 Random Forest의 성능이 가장 좋은 것으로 나타났다. 다른 두 모델과 달리, Random Forest는 여러 개의 분류 결과를 합산해서 최종 결과를 도출하기 때문에 치밀하고 섬세한 분류 작업이 가능하다. 물은 인간의 생존에 직결되는 만큼 한 번의 분류 작업만으로 섣불리 판단하게 되면 오염된 물과 깨끗한 물을 제대로 분류하지 못해 위험한 결과를 초래할 수 있다. 본 과제에서는 Random Forest를 안전한 물을 분류하기에 적합하다고 판단하여 해당 모델을 최종 모델로 선택한다. 

\

***

### 3.5) 중요한 변수 찾기

* 랜덤포레스트 모델을 최종 선택하기로 결정했으므로, 해당 모델에서 중요하다고 판단하는 변수를 살펴보자. 
* MeanDecreaseAccuracy : 모델 학습 시 각 변수의 초기 중요도를 설정한 후, 각 변수들이 섞이거나 제외된 상태에서의 모델 정확도 감소량을 측정하고 평균을 낸다. 평균 감소 정확도가 높은 변수를 중요한 변수로 간주한다.  
* MeanDecreaseGini : 어떤 변수 x로 트리를 분할하였을 때, 오차가 얼마나 줄었는지를 모든 트리에 대해 확인한다. 오차가 줄어든만큼 가산점을 부여해서 가장 많은 점수를 획득한 변수 순서대로 중요하다고 판단한다. 
```{r}
varImpPlot(rf_final)
paged_table(varimp_rf)
```

> 정확도와 지니계수 모두 aluminium, arsenic, cadmium 순으로 중요한 것으로 나타났다. 다만, aluminium의 중요도와 다른 변수들의 중요도 차이가 큰 것으로 보아 aluminium이 다른 변수에 비해 수질에 끼치는 영향력이 훨씬 크다고 볼 수 있다. 그 뒤를 이은 arsenic과 cadmium은 중요도 차이가 작은 것으로 보아 수질에 끼치는 영향력이 비슷하다고 볼 수 있다. 따라서 수질 검사 시 최우선으로 생각해야 할 변수는 aluminium, arsenic, cadmium이며, 
검사의 정확성을 높이고 싶다면 chloramine, perchlorate, chromium, silver까지 고려하는 것도 좋을 것이다. 

\
\
\


***


# D. 활용방안 
* 활용방안 
  + 수인성 질병 예방 : 아프리카와 같이 수자원이 부족한 국가를 위해 빗물을 식수로 활용하는 기술이 개발되고 있으나, 소비 가능성에 대한 의혹이 꾸준히 제기되고 있다. 따라서 음용 가능한 빗물과 그렇지 않은 빗물을 분류한다면, 해당 국가 사람들이 안전한 물을 마실 수 있도록 함으로써 오염수로 인한 감염병 전파를 막는다. 
  
  + 수질 적정기술 : 위생 시설처럼 물을 활용한 시설에서는 수질 검토가 필수적이다. 그러나 아프리카 같은 저소득 국가에서는 이러한 검사가 활발히 이루어지고 있지 않다. 이에 수질검사 키트 같은 적정기술의 개발이 활발해지고 있는 현시점에서, 수질에 영향을 끼치는 변수들에 대해 중요도를 측정하여 경쟁력을 갖춘 상품을 출시한다. 
  
  + 농업용수 공급 : 농업에서 사용되는 물의 품질은 농작물의 성장 및 생산에 직접적인 영향을 끼친다. 이때, 식수 분류 작업을 통해 물에서 미생물, 중금속, 화학물질 등의 오염 물질을 제거한다면, 깨끗하고 안전한 농업용수 공급이 가능해 농작물의 성장을 기대할 수 있다. 
  
  + 도시계획 개발 : 도시계획 개발에 착수할 때, 해당 지역의 식수원, 지하수가 안전한지 검사하는 데 활용되어 원활한 작업이 가능하도록 한다. 혹은 개발 도중 수질과 관련한 비상상황이 발생했을 때, 가장 의심되는 요소를 확인함으로써 행정상의 편의성을 증대할 수 있다.








